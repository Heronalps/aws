{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying images with pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's download three image classification models from the Apache MXNet [model zoo](http://mxnet.io/model_zoo/).\n",
    "* **VGG-16**: the 2014 classification winner at the [ImageNet Large Scale Visual Recognition Challenge](http://image-net.org/challenges/LSVRC).\n",
    "* **Inception v3**, an evolution of GoogleNet, the 2014 winner for object detection.\n",
    "* **ResNet-152**, the 2015 winner in multiple categories.\n",
    "\n",
    "All three models have been pre-trained on the ImageNet data set, which includes object and animal pictures sorted in 1,000 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://data.dmlc.ml/models/imagenet/vgg/vgg16-symbol.json -O vgg16-symbol.json\n",
    "!wget http://data.dmlc.ml/models/imagenet/vgg/vgg16-0000.params -O vgg16-0000.params\n",
    "!wget http://data.dmlc.ml/models/imagenet/inception-bn/Inception-BN-symbol.json -O Inception-BN-symbol.json\n",
    "!wget http://data.dmlc.ml/models/imagenet/inception-bn/Inception-BN-0126.params -O Inception-BN-0000.params\n",
    "!wget http://data.dmlc.ml/models/imagenet/resnet/152-layers/resnet-152-symbol.json -O resnet-152-symbol.json\n",
    "!wget http://data.dmlc.ml/models/imagenet/resnet/152-layers/resnet-152-0000.params -O resnet-152-0000.params\n",
    "!wget http://data.dmlc.ml/models/imagenet/synset.txt -O synset.txt\n",
    "!head -5 synset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import cv2,sys,time\n",
    "from collections import namedtuple\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "#print \"MXNet version: %s\"  % mx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, let's load a model. Here are the differents steps:\n",
    "* load **weights** and **model description** from file: MXNet calls this a **checkpoint**. In return, we get a *Symbol* object and the weights, a.k.a model parameters.\n",
    "* create a new *Module* and assign it the input *Symbol*. We could also a *context* parameter indicating where we want to run the model: the default value is cpu(0), but we’d use gpu(0) to run this on a GPU.\n",
    "* bind the input *Symbol* to input data. We have to call it ‘data’ because that’s its name in the **input layer** of the network (look at the first few lines of the JSON file).\n",
    "* define the **shape** of ‘data’ as 1 x 3 x 224 x 224. ‘224 x 224’ is the image resolution, that’s how the model was trained. ‘3’ is the number of channels : red, green and blue (in this order). ‘1’ is the batch size: we’ll predict one image at a time.\n",
    "\n",
    "We also need to load the 1,000 categories stored in the synset.txt file. We'll need the actual descriptions at prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadModel(modelname):\n",
    "        sym, arg_params, aux_params = mx.model.load_checkpoint(modelname, 0)\n",
    "        arg_params['prob_label'] = mx.nd.array([0])\n",
    "        arg_params['softmax_label'] = mx.nd.array([0])\n",
    "\n",
    "        mod = mx.mod.Module(symbol=sym)\n",
    "        #mod = mx.mod.Module(symbol=sym, context=mx.gpu(0))\n",
    "        mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "        mod.set_params(arg_params, aux_params)\n",
    "        return mod\n",
    "\n",
    "def loadCategories():\n",
    "        synsetfile = open('synset.txt', 'r')\n",
    "        synsets = []\n",
    "        for l in synsetfile:\n",
    "                synsets.append(l.rstrip())\n",
    "        return synsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a function to load an image from file. Remember that the model expects a 4-dimension *NDArray* holding the red, green and blue channels of a single 224 x 224 image. We’re going to use the **OpenCV** library to build this *NDArray* from our input image.\n",
    "\n",
    "Here are the steps:\n",
    "* read the image: this will return a **numpy array** shaped as (image height, image width, 3), with the three channels in **BGR** order (blue, green and red).\n",
    "* convert the image to **RGB**.\n",
    "* resize the image to **224 x 224**.\n",
    "* **reshape** the array from (image height, image width, 3) to (3, image height, image width).\n",
    "* add a **fourth dimension** and build the *NDArray*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareNDArray(filename):\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224,))\n",
    "        img = np.swapaxes(img, 0, 2)\n",
    "        img = np.swapaxes(img, 1, 2)\n",
    "        img = img[np.newaxis, :]\n",
    "        array = mx.nd.array(img)\n",
    "        #print array.shape\n",
    "        return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take care of prediction. Our parameters are an image, a model, a list of categories and the number of top categories we'd like to return. \n",
    "\n",
    "Remember that a *Module* object must feed data to a model in **batches**: the common way to do this is to use a **data iterator**. Here, we’d like to predict a single image, so although we could use a data iterator, it’d probably be overkill. Instead, let's create a named tuple, called *Batch*, which will act as a fake iterator by returning our input *NDArray* when its 'data' attribute is referenced.\n",
    "\n",
    "Once the image has been forwarded, the model outputs an *NDArray* holding **1,000 probabilities**, corresponding to the 1,000 categories it has been trained on: the *NDArray* has only one line since batch size is equal to 1. \n",
    "\n",
    "Let’s turn this into an array with *squeeze()*. Then, using *argsort()*, we create a second array holding the **index** of these probabilities sorted in **descending order**. Finally, we return the top n categories and their description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(filename, model, categories, n):\n",
    "        array = prepareNDArray(filename)\n",
    "        Batch = namedtuple('Batch', ['data'])\n",
    "        t1 = time.time()\n",
    "        model.forward(Batch([array]))\n",
    "        prob = model.get_outputs()[0].asnumpy()\n",
    "        t2 = time.time()\n",
    "        print(\"Predicted in %.2f microseconds\" % (t2-t1))\n",
    "        #print prob.shape\n",
    "        prob = np.squeeze(prob)\n",
    "        sortedprobindex = np.argsort(prob)[::-1]\n",
    "        #print sortedprobindex.shape\n",
    "        \n",
    "        topn = []\n",
    "        for i in sortedprobindex[0:n]:\n",
    "                topn.append((prob[i], categories[i]))\n",
    "        return topn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to put everything together. Let's load all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(modelname):\n",
    "        model = loadModel(modelname)\n",
    "        categories = loadCategories()\n",
    "        return model, categories\n",
    "\n",
    "vgg16,categories = init(\"vgg16\")\n",
    "resnet152,categories = init(\"resnet-152\")\n",
    "inceptionv3,categories = init(\"Inception-BN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use these models to classify our own images. Try as many as you'd like and don't forget to experiment with both CPU and GPU contexts. The difference in performance should be quite noticeable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"violin.jpg\"\n",
    "\n",
    "display(Image(filename=image))\n",
    "\n",
    "topn = 5\n",
    "print (\"*** VGG16\")\n",
    "print predict(image,vgg16,categories,topn)\n",
    "print (\"*** ResNet-152\")\n",
    "print predict(image,resnet152,categories,topn)\n",
    "print (\"*** Inception v3\")\n",
    "print predict(image,inceptionv3,categories,topn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
